{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# Import train and test set\n",
    "train = pd.read_csv('titanic-dataset/train.csv')\n",
    "test = pd.read_csv('titanic-dataset/test.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# Get target values\n",
    "y = train['Survived']\n",
    "\n",
    "# Drop the Survived column and remove it from further calculations\n",
    "train.drop(columns=['Survived'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train-test-split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.33, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NaN values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "PassengerId      0\nPclass           0\nName             0\nSex              0\nAge            118\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          462\nEmbarked         1\ndtype: int64"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "X_train.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "PassengerId                              1\nPclass                                 3.0\nName           Abbott, Mr. Rossmore Edward\nSex                                   male\nAge                                   24.0\nSibSp                                  0.0\nParch                                  0.0\nTicket                            CA. 2343\nFare                                  8.05\nCabin                          C23 C25 C27\nEmbarked                                 S\nName: 0, dtype: object"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use mode() function to get the most frequent value\n",
    "modes = X_train.mode().iloc[0]\n",
    "modes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# Use fillna with most frequent values\n",
    "X_train.fillna(modes, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "X_train.isna().sum().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get rid of 'Name', 'Ticket' abd 'Cabin' variables\n",
    "**NOTE**: We don't use those values because right now it is out of scope. However, information in those variables are crucial and very imortant! The best score in Kaggle on Titanic dataset is performed only on 'Name' variable! See this notebook for more information: https://www.kaggle.com/code/cdeotte/titanic-using-name-only-0-81818/notebook\n",
    "**NOTE**: It's very common in tabular data to use *categorical embeddings*. This is on *TODO* list right after finishing this notebook."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "X_train.drop(columns=['Name', 'Ticket', 'Cabin'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Label encoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "     index  PassengerId  Pclass     Sex   Age  SibSp  Parch      Fare Embarked\n0        6            7       1    male  54.0      0      0   51.8625        S\n1      718          719       3    male  24.0      0      0   15.5000        Q\n2      685          686       2    male  25.0      1      2   41.5792        C\n3       73           74       3    male  26.0      1      0   14.4542        C\n4      882          883       3  female  22.0      0      0   10.5167        S\n..     ...          ...     ...     ...   ...    ...    ...       ...      ...\n591    106          107       3  female  21.0      0      0    7.6500        S\n592    270          271       1    male  24.0      0      0   31.0000        S\n593    860          861       3    male  41.0      2      0   14.1083        S\n594    435          436       1  female  14.0      1      2  120.0000        S\n595    102          103       1    male  21.0      0      1   77.2875        S\n\n[596 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>7</td>\n      <td>1</td>\n      <td>male</td>\n      <td>54.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>51.8625</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>718</td>\n      <td>719</td>\n      <td>3</td>\n      <td>male</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>15.5000</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>685</td>\n      <td>686</td>\n      <td>2</td>\n      <td>male</td>\n      <td>25.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>41.5792</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>73</td>\n      <td>74</td>\n      <td>3</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>14.4542</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>882</td>\n      <td>883</td>\n      <td>3</td>\n      <td>female</td>\n      <td>22.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10.5167</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>591</th>\n      <td>106</td>\n      <td>107</td>\n      <td>3</td>\n      <td>female</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.6500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>592</th>\n      <td>270</td>\n      <td>271</td>\n      <td>1</td>\n      <td>male</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>31.0000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>860</td>\n      <td>861</td>\n      <td>3</td>\n      <td>male</td>\n      <td>41.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>14.1083</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>435</td>\n      <td>436</td>\n      <td>1</td>\n      <td>female</td>\n      <td>14.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>120.0000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>102</td>\n      <td>103</td>\n      <td>1</td>\n      <td>male</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>77.2875</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n<p>596 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore which variables are categorical\n",
    "X_train.reset_index(inplace=True)\n",
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# Categorical varaibles are Pclass, Sex, Embarked - use one-hot encoding for gender and label for embarked\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "one_hot_encoder = OneHotEncoder()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# Use one_hot_encode for gender\n",
    "gender = one_hot_encoder.fit_transform(X_train[['Sex']])\n",
    "gender_df = pd.DataFrame(gender.toarray(), columns=['Male', 'Female'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "             index  Pclass   Age  SibSp  Parch      Fare  Embarked  Male  \\\nPassengerId                                                                \n7                6       1  54.0      0      0   51.8625         2   0.0   \n719            718       3  24.0      0      0   15.5000         1   0.0   \n686            685       2  25.0      1      2   41.5792         0   0.0   \n74              73       3  26.0      1      0   14.4542         0   0.0   \n883            882       3  22.0      0      0   10.5167         2   1.0   \n...            ...     ...   ...    ...    ...       ...       ...   ...   \n107            106       3  21.0      0      0    7.6500         2   1.0   \n271            270       1  24.0      0      0   31.0000         2   0.0   \n861            860       3  41.0      2      0   14.1083         2   0.0   \n436            435       1  14.0      1      2  120.0000         2   1.0   \n103            102       1  21.0      0      1   77.2875         2   0.0   \n\n             Female  \nPassengerId          \n7               1.0  \n719             1.0  \n686             1.0  \n74              1.0  \n883             0.0  \n...             ...  \n107             0.0  \n271             1.0  \n861             1.0  \n436             0.0  \n103             1.0  \n\n[596 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>Male</th>\n      <th>Female</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>6</td>\n      <td>1</td>\n      <td>54.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>51.8625</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>719</th>\n      <td>718</td>\n      <td>3</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>15.5000</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>686</th>\n      <td>685</td>\n      <td>2</td>\n      <td>25.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>41.5792</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>73</td>\n      <td>3</td>\n      <td>26.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>14.4542</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>883</th>\n      <td>882</td>\n      <td>3</td>\n      <td>22.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10.5167</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>106</td>\n      <td>3</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.6500</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>271</th>\n      <td>270</td>\n      <td>1</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>31.0000</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>861</th>\n      <td>860</td>\n      <td>3</td>\n      <td>41.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>14.1083</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>436</th>\n      <td>435</td>\n      <td>1</td>\n      <td>14.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>120.0000</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>102</td>\n      <td>1</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>77.2875</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>596 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge train with encoded gender\n",
    "X_train = pd.concat([X_train, gender_df], axis=1)\n",
    "\n",
    "# Drop unused column\n",
    "X_train.drop(columns=['Sex'], inplace=True)\n",
    "\n",
    "# Encode 'Embarked' with label encoder\n",
    "X_train['Embarked'] = label_encoder.fit_transform(X_train['Embarked'])\n",
    "\n",
    "# Set PassangerID as index\n",
    "X_train.set_index('PassengerId', inplace=True)\n",
    "\n",
    "# Print\n",
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use the same preprocessing techniques for test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# Use fillna with most frequent values\n",
    "X_test.fillna(modes, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "X_test.reset_index(inplace=True)\n",
    "\n",
    "X_test.drop(columns=['Name', 'Ticket', 'Cabin'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "     Male  Female\n0     0.0     1.0\n1     0.0     1.0\n2     0.0     1.0\n3     1.0     0.0\n4     1.0     0.0\n..    ...     ...\n290   0.0     1.0\n291   0.0     1.0\n292   1.0     0.0\n293   1.0     0.0\n294   0.0     1.0\n\n[295 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Male</th>\n      <th>Female</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>290</th>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>291</th>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>292</th>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>293</th>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>294</th>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>295 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use one_hot_encode for gender\n",
    "gender_test = one_hot_encoder.transform(X_test[['Sex']])\n",
    "gender_test_df = pd.DataFrame(gender_test.toarray(), columns=['Male', 'Female'])\n",
    "gender_test_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "             index  Pclass   Age  SibSp  Parch     Fare  Embarked  Male  \\\nPassengerId                                                               \n710            709       3  24.0      1      1  15.2458         0   0.0   \n440            439       2  31.0      0      0  10.5000         2   0.0   \n841            840       3  20.0      0      0   7.9250         2   0.0   \n721            720       2   6.0      0      1  33.0000         2   1.0   \n40              39       3  14.0      1      0  11.2417         0   1.0   \n...            ...     ...   ...    ...    ...      ...       ...   ...   \n716            715       3  19.0      0      0   7.6500         2   0.0   \n526            525       3  40.5      0      0   7.7500         1   0.0   \n382            381       3   1.0      0      2  15.7417         0   1.0   \n141            140       3  24.0      0      2  15.2458         0   1.0   \n174            173       3  21.0      0      0   7.9250         2   0.0   \n\n             Female  \nPassengerId          \n710             1.0  \n440             1.0  \n841             1.0  \n721             0.0  \n40              0.0  \n...             ...  \n716             1.0  \n526             1.0  \n382             0.0  \n141             0.0  \n174             1.0  \n\n[295 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>Male</th>\n      <th>Female</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>710</th>\n      <td>709</td>\n      <td>3</td>\n      <td>24.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>15.2458</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>440</th>\n      <td>439</td>\n      <td>2</td>\n      <td>31.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10.5000</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>841</th>\n      <td>840</td>\n      <td>3</td>\n      <td>20.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>721</th>\n      <td>720</td>\n      <td>2</td>\n      <td>6.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>33.0000</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>39</td>\n      <td>3</td>\n      <td>14.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>11.2417</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>716</th>\n      <td>715</td>\n      <td>3</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.6500</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>526</th>\n      <td>525</td>\n      <td>3</td>\n      <td>40.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.7500</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>382</th>\n      <td>381</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>15.7417</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>141</th>\n      <td>140</td>\n      <td>3</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>15.2458</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>174</th>\n      <td>173</td>\n      <td>3</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>295 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge train with encoded gender\n",
    "X_test = pd.concat([X_test, gender_test_df], axis=1)\n",
    "\n",
    "# Drop unused column\n",
    "X_test.drop(columns=['Sex'], inplace=True)\n",
    "\n",
    "# Encode 'Embarked' with label encoder\n",
    "X_test['Embarked'] = label_encoder.transform(X_test['Embarked'])\n",
    "\n",
    "# Set PassangerID as index\n",
    "X_test.set_index('PassengerId', inplace=True)\n",
    "\n",
    "# Print\n",
    "X_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "(596, 9)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "(295, 9)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check whether the dimensions are correct\n",
    "display(X_train.shape)\n",
    "display(X_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "n_features = X_train.shape[1]\n",
    "\n",
    "# Define the class\n",
    "class TitanicNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TitanicNetwork, self).__init__()\n",
    "\n",
    "        # Number of input features is 9\n",
    "        self.layer_in = nn.Linear(n_features, 63)\n",
    "        self.layer_2 = nn.Linear(63, 63)\n",
    "        self.layer_out = nn.Linear(63,1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(63)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(63)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_in(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        # x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "titanic_network = TitanicNetwork()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Note**: that we did not use the Sigmoid activation in our final layer during training. That’s because, we use the nn.BCEWithLogitsLoss() loss function which automatically applies the Sigmoid activation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "TitanicNetwork(\n  (layer_in): Linear(in_features=9, out_features=63, bias=True)\n  (layer_2): Linear(in_features=63, out_features=63, bias=True)\n  (layer_out): Linear(in_features=63, out_features=1, bias=True)\n  (relu): ReLU()\n  (batchnorm1): BatchNorm1d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (batchnorm2): BatchNorm1d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n)"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = TitanicNetwork()\n",
    "\n",
    "# Specify the device type responsible to load model into memory\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TitanicNetwork(\n",
      "  (layer_in): Linear(in_features=9, out_features=63, bias=True)\n",
      "  (layer_2): Linear(in_features=63, out_features=63, bias=True)\n",
      "  (layer_out): Linear(in_features=63, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (batchnorm1): BatchNorm1d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# print(list(model.named_parameters()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# Init loss function (Binary Cross Entropy Loss) (we assume that target is equally distributed)\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DataLoaders and Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before training, we should implement custom Dataset class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "class TitanicTrainDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Return the single observation, including both independent and dependent variable \"\"\"\n",
    "        # Convert idx from tensor to list due to pandas bug (that arises when using pytorch's random_split)\n",
    "        # if isinstance(index, torch.Tensor):\n",
    "        #     index = index.tolist()\n",
    "\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        # return [self.X_data.iloc[index].values, self.y_data[index]]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Return the number of rows from tabular data \"\"\"\n",
    "        return len(self.X_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "class TitanicTestDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Return the single observation, including only independent variable \"\"\"\n",
    "        if isinstance(index, torch.Tensor):\n",
    "            index = index.tolist()\n",
    "\n",
    "        return self.X_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Return the number of rows from tabular data \"\"\"\n",
    "        return len(self.X_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "train_data = TitanicTrainDataset(torch.Tensor(X_train.values), torch.Tensor(y_train.values))\n",
    "test_data = TitanicTestDataset(torch.Tensor(X_test.values))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "596"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test len method\n",
    "train_data.__len__()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "891"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.__len__()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "0    374\n1    222\nName: Survived, dtype: int64"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([718.0000,   3.0000,  24.0000,   0.0000,   0.0000,  15.5000,   1.0000,\n           0.0000,   1.0000]),\n tensor(0.))"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test getitem method\n",
    "train_data.__getitem__(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "# Initialize dataloaders\n",
    "BATCH_SIZE_TRAIN = 64\n",
    "BATCH_SIZE_TEST = 1\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE_TEST, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "# Define binary accuracy function\n",
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "\n",
    "    return acc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.66219 | Acc: 58.500\n",
      "Epoch 002: | Loss: 0.63690 | Acc: 65.700\n",
      "Epoch 003: | Loss: 0.61471 | Acc: 68.200\n",
      "Epoch 004: | Loss: 0.60692 | Acc: 68.100\n",
      "Epoch 005: | Loss: 0.62201 | Acc: 67.900\n",
      "Epoch 006: | Loss: 0.59789 | Acc: 69.100\n",
      "Epoch 007: | Loss: 0.59691 | Acc: 69.700\n",
      "Epoch 008: | Loss: 0.59938 | Acc: 67.800\n",
      "Epoch 009: | Loss: 0.60446 | Acc: 67.500\n",
      "Epoch 010: | Loss: 0.58770 | Acc: 68.500\n",
      "Epoch 011: | Loss: 0.58555 | Acc: 69.300\n",
      "Epoch 012: | Loss: 0.58482 | Acc: 69.500\n",
      "Epoch 013: | Loss: 0.57564 | Acc: 69.600\n",
      "Epoch 014: | Loss: 0.57591 | Acc: 69.100\n",
      "Epoch 015: | Loss: 0.57833 | Acc: 70.300\n",
      "Epoch 016: | Loss: 0.56751 | Acc: 71.900\n",
      "Epoch 017: | Loss: 0.56723 | Acc: 71.000\n",
      "Epoch 018: | Loss: 0.56438 | Acc: 68.900\n",
      "Epoch 019: | Loss: 0.58337 | Acc: 70.700\n",
      "Epoch 020: | Loss: 0.57829 | Acc: 69.800\n",
      "Epoch 021: | Loss: 0.56777 | Acc: 69.600\n",
      "Epoch 022: | Loss: 0.57171 | Acc: 69.600\n",
      "Epoch 023: | Loss: 0.56866 | Acc: 70.100\n",
      "Epoch 024: | Loss: 0.55476 | Acc: 71.800\n",
      "Epoch 025: | Loss: 0.55448 | Acc: 72.500\n",
      "Epoch 026: | Loss: 0.54821 | Acc: 71.300\n",
      "Epoch 027: | Loss: 0.53942 | Acc: 71.900\n",
      "Epoch 028: | Loss: 0.54495 | Acc: 71.800\n",
      "Epoch 029: | Loss: 0.51795 | Acc: 72.900\n",
      "Epoch 030: | Loss: 0.53764 | Acc: 73.400\n",
      "Epoch 031: | Loss: 0.52395 | Acc: 74.300\n",
      "Epoch 032: | Loss: 0.52095 | Acc: 74.600\n",
      "Epoch 033: | Loss: 0.52852 | Acc: 73.800\n",
      "Epoch 034: | Loss: 0.51312 | Acc: 76.200\n",
      "Epoch 035: | Loss: 0.51798 | Acc: 74.800\n",
      "Epoch 036: | Loss: 0.49743 | Acc: 75.100\n",
      "Epoch 037: | Loss: 0.48309 | Acc: 78.000\n",
      "Epoch 038: | Loss: 0.49664 | Acc: 75.200\n",
      "Epoch 039: | Loss: 0.49938 | Acc: 76.300\n",
      "Epoch 040: | Loss: 0.48115 | Acc: 78.500\n",
      "Epoch 041: | Loss: 0.49125 | Acc: 74.900\n",
      "Epoch 042: | Loss: 0.48903 | Acc: 77.100\n",
      "Epoch 043: | Loss: 0.48708 | Acc: 77.900\n",
      "Epoch 044: | Loss: 0.47777 | Acc: 78.200\n",
      "Epoch 045: | Loss: 0.48525 | Acc: 76.100\n",
      "Epoch 046: | Loss: 0.45719 | Acc: 77.900\n",
      "Epoch 047: | Loss: 0.44056 | Acc: 79.200\n",
      "Epoch 048: | Loss: 0.45582 | Acc: 77.900\n",
      "Epoch 049: | Loss: 0.45620 | Acc: 79.700\n",
      "Epoch 050: | Loss: 0.42894 | Acc: 80.500\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "loss_list = []\n",
    "validate_loss_list = []\n",
    "\n",
    "# Prepare model for training (default state)\n",
    "model.train()\n",
    "\n",
    "for e in range(1, EPOCHS+1):\n",
    "\n",
    "    # Init loss and acc per epoch to zero\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    # For loop to get our data in batches from dataloader\n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "\n",
    "        # Load batches into memory (device)\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        # Set .grad attribute of all tensors to zero (otherwise we would accumulate it with .backwards())\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass (use input data to make prediction)\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        # Calculate loss based on prediction and true value\n",
    "        loss = loss_function(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # We backpropagate this error through the network\n",
    "        # The gradient is calculated for tensors which requires_grad=True\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust each parameter (weight and bias) by its gradient stored in .grad\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate loss and accuracy\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_dataloader):.5f} | Acc: {epoch_acc/len(train_dataloader):.3f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(loss_list)\n",
    "# plt.legend((\"Training Loss\", \"Validation Loss\"))\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"BCE Loss\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "\n",
    "# Prepare model for testing\n",
    "model.eval()\n",
    "\n",
    "# We don't want to perform backpropagation\n",
    "with torch.no_grad():\n",
    "\n",
    "    # Go through batches\n",
    "    for X_batch in test_dataloader:\n",
    "\n",
    "        # Load batch into memory\n",
    "        X_batch = X_batch.to(device)\n",
    "\n",
    "        # Get the result\n",
    "        y_test_pred = model(X_batch)\n",
    "\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "\n",
    "        # Round probabilities to 0 or 1\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "\n",
    "        # Convert tensor to numpy object\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "# Flatten the list to use confusion matrix and classification report\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[147,  28],\n       [ 43,  77]])"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Plot confusion matrix\n",
    "confusion_matrix(y_test, y_pred_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.84      0.81       175\n",
      "           1       0.73      0.64      0.68       120\n",
      "\n",
      "    accuracy                           0.76       295\n",
      "   macro avg       0.75      0.74      0.74       295\n",
      "weighted avg       0.76      0.76      0.76       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_list))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Submit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "             index  Pclass   Age  SibSp  Parch      Fare  Embarked  Male  \\\nPassengerId                                                                \n892              0       3  34.5      0      0    7.8292         1   0.0   \n893              1       3  47.0      1      0    7.0000         2   1.0   \n894              2       2  62.0      0      0    9.6875         1   0.0   \n895              3       3  27.0      0      0    8.6625         2   0.0   \n896              4       3  22.0      1      1   12.2875         2   1.0   \n...            ...     ...   ...    ...    ...       ...       ...   ...   \n1305           413       3  24.0      0      0    8.0500         2   0.0   \n1306           414       1  39.0      0      0  108.9000         0   1.0   \n1307           415       3  38.5      0      0    7.2500         2   0.0   \n1308           416       3  24.0      0      0    8.0500         2   0.0   \n1309           417       3  24.0      1      1   22.3583         0   0.0   \n\n             Female  \nPassengerId          \n892             1.0  \n893             0.0  \n894             1.0  \n895             1.0  \n896             0.0  \n...             ...  \n1305            1.0  \n1306            0.0  \n1307            1.0  \n1308            1.0  \n1309            1.0  \n\n[418 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>Male</th>\n      <th>Female</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>892</th>\n      <td>0</td>\n      <td>3</td>\n      <td>34.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.8292</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>893</th>\n      <td>1</td>\n      <td>3</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.0000</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>894</th>\n      <td>2</td>\n      <td>2</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9.6875</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>895</th>\n      <td>3</td>\n      <td>3</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.6625</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>896</th>\n      <td>4</td>\n      <td>3</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>12.2875</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1305</th>\n      <td>413</td>\n      <td>3</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1306</th>\n      <td>414</td>\n      <td>1</td>\n      <td>39.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>108.9000</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1307</th>\n      <td>415</td>\n      <td>3</td>\n      <td>38.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1308</th>\n      <td>416</td>\n      <td>3</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1309</th>\n      <td>417</td>\n      <td>3</td>\n      <td>24.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>22.3583</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>418 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use fillna with most frequent values\n",
    "test.fillna(modes, inplace=True)\n",
    "test.reset_index(inplace=True)\n",
    "\n",
    "test.drop(columns=['Name', 'Ticket', 'Cabin'], inplace=True)\n",
    "\n",
    "# Use one_hot_encode for gender\n",
    "gender_test = one_hot_encoder.transform(test[['Sex']])\n",
    "gender_test_df = pd.DataFrame(gender_test.toarray(), columns=['Male', 'Female'])\n",
    "\n",
    "# Merge train with encoded gender\n",
    "test = pd.concat([test, gender_test_df], axis=1)\n",
    "\n",
    "# Drop unused column\n",
    "test.drop(columns=['Sex'], inplace=True)\n",
    "\n",
    "# Encode 'Embarked' with label encoder\n",
    "test['Embarked'] = label_encoder.transform(test['Embarked'])\n",
    "\n",
    "# Set PassangerID as index\n",
    "test.set_index('PassengerId', inplace=True)\n",
    "\n",
    "# Print\n",
    "test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "# Apply model on test data\n",
    "sub_X = torch.tensor(test.values)\n",
    "\n",
    "# Get the results\n",
    "sub_y = titanic_network(sub_X.float())\n",
    "\n",
    "# Get survived\n",
    "survived = torch.heaviside(sub_y, values=torch.tensor([0.0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "test.reset_index(inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "test['Survived'] = survived.detach().numpy().astype(int)\n",
    "sub_df = test[['PassengerId', 'Survived']]\n",
    "sub_df.to_csv('submission/sub-pytorch.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId,Survived\r\n",
      "892,0\r\n",
      "893,0\r\n",
      "894,0\r\n",
      "895,0\r\n",
      "896,0\r\n",
      "897,0\r\n",
      "898,1\r\n",
      "899,0\r\n",
      "900,1\r\n"
     ]
    }
   ],
   "source": [
    "!head 'submission/sub-fastai.csv'"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
