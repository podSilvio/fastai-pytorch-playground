{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "outputs": [],
   "source": [
    "# Import train and test set\n",
    "train = pd.read_csv('titanic-dataset/train.csv')\n",
    "test = pd.read_csv('titanic-dataset/test.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "outputs": [],
   "source": [
    "# Get target values\n",
    "y = train['Survived']\n",
    "\n",
    "# Drop the Survived column and remove it from further calculations\n",
    "train.drop(columns=['Survived'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train-test-split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.33, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NaN values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "outputs": [
    {
     "data": {
      "text/plain": "PassengerId      0\nPclass           0\nName             0\nSex              0\nAge            118\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          462\nEmbarked         1\ndtype: int64"
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "X_train.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "outputs": [
    {
     "data": {
      "text/plain": "PassengerId                              1\nPclass                                 3.0\nName           Abbott, Mr. Rossmore Edward\nSex                                   male\nAge                                   24.0\nSibSp                                  0.0\nParch                                  0.0\nTicket                            CA. 2343\nFare                                  8.05\nCabin                          C23 C25 C27\nEmbarked                                 S\nName: 0, dtype: object"
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use mode() function to get the most frequent value\n",
    "modes = X_train.mode().iloc[0]\n",
    "modes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "outputs": [],
   "source": [
    "# Use fillna with most frequent values\n",
    "X_train.fillna(modes, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "X_train.isna().sum().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get rid of 'Name', 'Ticket' abd 'Cabin' variables\n",
    "**NOTE**: We don't use those values because right now it is out of scope. However, information in those variables are crucial and very imortant! The best score in Kaggle on Titanic dataset is performed only on 'Name' variable! See this notebook for more information: https://www.kaggle.com/code/cdeotte/titanic-using-name-only-0-81818/notebook\n",
    "**NOTE**: It's very common in tabular data to use *categorical embeddings*. This is on *TODO* list right after finishing this notebook."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "outputs": [],
   "source": [
    "X_train.drop(columns=['Name', 'Ticket', 'Cabin'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Label encoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "outputs": [
    {
     "data": {
      "text/plain": "     index  PassengerId  Pclass     Sex   Age  SibSp  Parch      Fare Embarked\n0        6            7       1    male  54.0      0      0   51.8625        S\n1      718          719       3    male  24.0      0      0   15.5000        Q\n2      685          686       2    male  25.0      1      2   41.5792        C\n3       73           74       3    male  26.0      1      0   14.4542        C\n4      882          883       3  female  22.0      0      0   10.5167        S\n..     ...          ...     ...     ...   ...    ...    ...       ...      ...\n591    106          107       3  female  21.0      0      0    7.6500        S\n592    270          271       1    male  24.0      0      0   31.0000        S\n593    860          861       3    male  41.0      2      0   14.1083        S\n594    435          436       1  female  14.0      1      2  120.0000        S\n595    102          103       1    male  21.0      0      1   77.2875        S\n\n[596 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>7</td>\n      <td>1</td>\n      <td>male</td>\n      <td>54.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>51.8625</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>718</td>\n      <td>719</td>\n      <td>3</td>\n      <td>male</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>15.5000</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>685</td>\n      <td>686</td>\n      <td>2</td>\n      <td>male</td>\n      <td>25.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>41.5792</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>73</td>\n      <td>74</td>\n      <td>3</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>14.4542</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>882</td>\n      <td>883</td>\n      <td>3</td>\n      <td>female</td>\n      <td>22.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10.5167</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>591</th>\n      <td>106</td>\n      <td>107</td>\n      <td>3</td>\n      <td>female</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.6500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>592</th>\n      <td>270</td>\n      <td>271</td>\n      <td>1</td>\n      <td>male</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>31.0000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>860</td>\n      <td>861</td>\n      <td>3</td>\n      <td>male</td>\n      <td>41.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>14.1083</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>435</td>\n      <td>436</td>\n      <td>1</td>\n      <td>female</td>\n      <td>14.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>120.0000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>102</td>\n      <td>103</td>\n      <td>1</td>\n      <td>male</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>77.2875</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n<p>596 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore which variables are categorical\n",
    "X_train.reset_index(inplace=True)\n",
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "outputs": [],
   "source": [
    "# Categorical varaibles are Pclass, Sex, Embarked - use one-hot encoding for gender and label for embarked\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "one_hot_encoder = OneHotEncoder()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "outputs": [],
   "source": [
    "# Use one_hot_encode for gender\n",
    "gender = one_hot_encoder.fit_transform(X_train[['Sex']])\n",
    "gender_df = pd.DataFrame(gender.toarray(), columns=['Male', 'Female'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "outputs": [
    {
     "data": {
      "text/plain": "             index  Pclass   Age  SibSp  Parch      Fare  Embarked  Male  \\\nPassengerId                                                                \n7                6       1  54.0      0      0   51.8625         2   0.0   \n719            718       3  24.0      0      0   15.5000         1   0.0   \n686            685       2  25.0      1      2   41.5792         0   0.0   \n74              73       3  26.0      1      0   14.4542         0   0.0   \n883            882       3  22.0      0      0   10.5167         2   1.0   \n...            ...     ...   ...    ...    ...       ...       ...   ...   \n107            106       3  21.0      0      0    7.6500         2   1.0   \n271            270       1  24.0      0      0   31.0000         2   0.0   \n861            860       3  41.0      2      0   14.1083         2   0.0   \n436            435       1  14.0      1      2  120.0000         2   1.0   \n103            102       1  21.0      0      1   77.2875         2   0.0   \n\n             Female  \nPassengerId          \n7               1.0  \n719             1.0  \n686             1.0  \n74              1.0  \n883             0.0  \n...             ...  \n107             0.0  \n271             1.0  \n861             1.0  \n436             0.0  \n103             1.0  \n\n[596 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>Male</th>\n      <th>Female</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>6</td>\n      <td>1</td>\n      <td>54.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>51.8625</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>719</th>\n      <td>718</td>\n      <td>3</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>15.5000</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>686</th>\n      <td>685</td>\n      <td>2</td>\n      <td>25.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>41.5792</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>73</td>\n      <td>3</td>\n      <td>26.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>14.4542</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>883</th>\n      <td>882</td>\n      <td>3</td>\n      <td>22.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10.5167</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>106</td>\n      <td>3</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.6500</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>271</th>\n      <td>270</td>\n      <td>1</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>31.0000</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>861</th>\n      <td>860</td>\n      <td>3</td>\n      <td>41.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>14.1083</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>436</th>\n      <td>435</td>\n      <td>1</td>\n      <td>14.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>120.0000</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>102</td>\n      <td>1</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>77.2875</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>596 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge train with encoded gender\n",
    "X_train = pd.concat([X_train, gender_df], axis=1)\n",
    "\n",
    "# Drop unused column\n",
    "X_train.drop(columns=['Sex'], inplace=True)\n",
    "\n",
    "# Encode 'Embarked' with label encoder\n",
    "X_train['Embarked'] = label_encoder.fit_transform(X_train['Embarked'])\n",
    "\n",
    "# Set PassangerID as index\n",
    "X_train.set_index('PassengerId', inplace=True)\n",
    "\n",
    "# Print\n",
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use the same preprocessing techniques for test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "outputs": [],
   "source": [
    "# Use fillna with most frequent values\n",
    "X_test.fillna(modes, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "outputs": [],
   "source": [
    "X_test.reset_index(inplace=True)\n",
    "\n",
    "X_test.drop(columns=['Name', 'Ticket', 'Cabin'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "outputs": [
    {
     "data": {
      "text/plain": "     Male  Female\n0     0.0     1.0\n1     0.0     1.0\n2     0.0     1.0\n3     1.0     0.0\n4     1.0     0.0\n..    ...     ...\n290   0.0     1.0\n291   0.0     1.0\n292   1.0     0.0\n293   1.0     0.0\n294   0.0     1.0\n\n[295 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Male</th>\n      <th>Female</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>290</th>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>291</th>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>292</th>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>293</th>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>294</th>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>295 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use one_hot_encode for gender\n",
    "gender_test = one_hot_encoder.transform(X_test[['Sex']])\n",
    "gender_test_df = pd.DataFrame(gender_test.toarray(), columns=['Male', 'Female'])\n",
    "gender_test_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "outputs": [
    {
     "data": {
      "text/plain": "             index  Pclass   Age  SibSp  Parch     Fare  Embarked  Male  \\\nPassengerId                                                               \n710            709       3  24.0      1      1  15.2458         0   0.0   \n440            439       2  31.0      0      0  10.5000         2   0.0   \n841            840       3  20.0      0      0   7.9250         2   0.0   \n721            720       2   6.0      0      1  33.0000         2   1.0   \n40              39       3  14.0      1      0  11.2417         0   1.0   \n...            ...     ...   ...    ...    ...      ...       ...   ...   \n716            715       3  19.0      0      0   7.6500         2   0.0   \n526            525       3  40.5      0      0   7.7500         1   0.0   \n382            381       3   1.0      0      2  15.7417         0   1.0   \n141            140       3  24.0      0      2  15.2458         0   1.0   \n174            173       3  21.0      0      0   7.9250         2   0.0   \n\n             Female  \nPassengerId          \n710             1.0  \n440             1.0  \n841             1.0  \n721             0.0  \n40              0.0  \n...             ...  \n716             1.0  \n526             1.0  \n382             0.0  \n141             0.0  \n174             1.0  \n\n[295 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>Male</th>\n      <th>Female</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>710</th>\n      <td>709</td>\n      <td>3</td>\n      <td>24.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>15.2458</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>440</th>\n      <td>439</td>\n      <td>2</td>\n      <td>31.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10.5000</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>841</th>\n      <td>840</td>\n      <td>3</td>\n      <td>20.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>721</th>\n      <td>720</td>\n      <td>2</td>\n      <td>6.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>33.0000</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>39</td>\n      <td>3</td>\n      <td>14.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>11.2417</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>716</th>\n      <td>715</td>\n      <td>3</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.6500</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>526</th>\n      <td>525</td>\n      <td>3</td>\n      <td>40.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.7500</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>382</th>\n      <td>381</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>15.7417</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>141</th>\n      <td>140</td>\n      <td>3</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>15.2458</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>174</th>\n      <td>173</td>\n      <td>3</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>295 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge train with encoded gender\n",
    "X_test = pd.concat([X_test, gender_test_df], axis=1)\n",
    "\n",
    "# Drop unused column\n",
    "X_test.drop(columns=['Sex'], inplace=True)\n",
    "\n",
    "# Encode 'Embarked' with label encoder\n",
    "X_test['Embarked'] = label_encoder.transform(X_test['Embarked'])\n",
    "\n",
    "# Set PassangerID as index\n",
    "X_test.set_index('PassengerId', inplace=True)\n",
    "\n",
    "# Print\n",
    "X_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "outputs": [
    {
     "data": {
      "text/plain": "(596, 9)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "(295, 9)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check whether the dimensions are correct\n",
    "display(X_train.shape)\n",
    "display(X_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "outputs": [],
   "source": [
    "n_features = X_train.shape[1]\n",
    "\n",
    "# Define the class\n",
    "class TitanicNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TitanicNetwork, self).__init__()\n",
    "\n",
    "        # Number of input features is 9\n",
    "        self.layer_in = nn.Linear(n_features, 63)\n",
    "        self.layer_2 = nn.Linear(63, 63)\n",
    "        self.layer_out = nn.Linear(63,1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(63)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(63)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_in(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "titanic_network = TitanicNetwork()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Note**: that we did not use the Sigmoid activation in our final layer during training. That’s because, we use the nn.BCEWithLogitsLoss() loss function which automatically applies the Sigmoid activation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "outputs": [
    {
     "data": {
      "text/plain": "TitanicNetwork(\n  (layer_in): Linear(in_features=9, out_features=63, bias=True)\n  (layer_2): Linear(in_features=63, out_features=63, bias=True)\n  (layer_out): Linear(in_features=63, out_features=1, bias=True)\n  (relu): ReLU()\n  (dropout): Dropout(p=0.1, inplace=False)\n  (batchnorm1): BatchNorm1d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (batchnorm2): BatchNorm1d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n)"
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = TitanicNetwork()\n",
    "\n",
    "# Specify the device type responsible to load model into memory\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TitanicNetwork(\n",
      "  (layer_in): Linear(in_features=9, out_features=63, bias=True)\n",
      "  (layer_2): Linear(in_features=63, out_features=63, bias=True)\n",
      "  (layer_out): Linear(in_features=63, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('layer_in.weight', Parameter containing:\n",
      "tensor([[ 0.2511, -0.2858, -0.2811,  0.0361, -0.0139,  0.0239,  0.2622, -0.2875,\n",
      "          0.0937],\n",
      "        [ 0.2804, -0.1831,  0.0699, -0.0208,  0.0314, -0.1375,  0.1234, -0.0567,\n",
      "         -0.3042],\n",
      "        [ 0.0486,  0.0487, -0.2226,  0.0495,  0.0342,  0.1533, -0.2531,  0.1877,\n",
      "         -0.0346],\n",
      "        [-0.1577,  0.1173,  0.1827,  0.3192, -0.0918, -0.2573, -0.2096, -0.0716,\n",
      "          0.0962],\n",
      "        [ 0.2163,  0.2198,  0.1493,  0.0567, -0.1689,  0.0474,  0.0701,  0.0451,\n",
      "          0.2111],\n",
      "        [-0.1510,  0.3316, -0.1474,  0.1275, -0.1062, -0.1795, -0.2702, -0.0518,\n",
      "          0.1759],\n",
      "        [-0.1815, -0.1764,  0.0286,  0.1765, -0.3160,  0.1961,  0.0789, -0.2222,\n",
      "          0.1565],\n",
      "        [ 0.3032,  0.0152,  0.0519, -0.0879,  0.2113, -0.1496, -0.2094, -0.0422,\n",
      "         -0.1987],\n",
      "        [-0.2176, -0.1315,  0.0909, -0.0202, -0.2675, -0.0486, -0.2967, -0.0855,\n",
      "          0.2501],\n",
      "        [ 0.1660, -0.2773, -0.0044, -0.0480,  0.2530, -0.0777, -0.1371,  0.1911,\n",
      "         -0.0895],\n",
      "        [-0.1717,  0.1994,  0.2009,  0.1660, -0.0805, -0.0823,  0.2826, -0.0803,\n",
      "          0.0221],\n",
      "        [ 0.0772,  0.0755, -0.0032,  0.2074, -0.1211, -0.1735,  0.0421, -0.3298,\n",
      "         -0.1680],\n",
      "        [-0.0614, -0.2513, -0.2797, -0.1054, -0.1112,  0.0949, -0.1093, -0.2096,\n",
      "         -0.2005],\n",
      "        [-0.2048,  0.0115, -0.0875, -0.0246, -0.0637, -0.1178,  0.2388, -0.1643,\n",
      "         -0.2936],\n",
      "        [-0.0477, -0.1745, -0.3020, -0.0152,  0.1970,  0.0226, -0.0481, -0.2048,\n",
      "         -0.2075],\n",
      "        [-0.2200,  0.0138, -0.1025,  0.0984,  0.0024, -0.1295, -0.3215, -0.0653,\n",
      "         -0.2903],\n",
      "        [-0.0664,  0.3199, -0.1607,  0.2176,  0.3125,  0.1202,  0.3091, -0.2931,\n",
      "          0.1016],\n",
      "        [ 0.1044, -0.0661,  0.0417, -0.0143,  0.1232, -0.1878,  0.0958,  0.1795,\n",
      "         -0.1465],\n",
      "        [-0.2528, -0.3262, -0.2614, -0.1198, -0.1492,  0.0026, -0.1116,  0.3174,\n",
      "          0.2281],\n",
      "        [-0.2530,  0.0708, -0.2743, -0.1874,  0.1404, -0.2216,  0.1023,  0.2672,\n",
      "         -0.1523],\n",
      "        [ 0.1297, -0.0488, -0.3024,  0.1153,  0.0837, -0.2311, -0.2102, -0.1639,\n",
      "         -0.0109],\n",
      "        [-0.1928,  0.0900,  0.3314,  0.1554, -0.1286,  0.2198, -0.0338,  0.1610,\n",
      "         -0.1325],\n",
      "        [-0.0920,  0.1638,  0.0026, -0.1321,  0.1448,  0.3085, -0.1926, -0.0435,\n",
      "          0.3011],\n",
      "        [-0.1505, -0.1445,  0.0220,  0.1476,  0.3104,  0.1485, -0.0250,  0.1168,\n",
      "         -0.2391],\n",
      "        [ 0.2758,  0.3329,  0.0243, -0.1216, -0.2000, -0.2786, -0.2716, -0.2930,\n",
      "         -0.2514],\n",
      "        [ 0.3181, -0.0323,  0.2936,  0.1600,  0.0430, -0.1882, -0.0667, -0.3330,\n",
      "          0.3119],\n",
      "        [-0.2239,  0.2687, -0.1704,  0.3059,  0.1294, -0.3232,  0.1398,  0.0125,\n",
      "          0.2951],\n",
      "        [ 0.2863, -0.2707, -0.0722, -0.2564, -0.3071, -0.0079, -0.1590,  0.1934,\n",
      "         -0.2747],\n",
      "        [-0.2739,  0.2596, -0.2003,  0.2011, -0.1244, -0.3217, -0.2836, -0.0159,\n",
      "         -0.0118],\n",
      "        [-0.0790,  0.1547,  0.0802, -0.3012,  0.1655, -0.0676,  0.2512,  0.1507,\n",
      "         -0.1111],\n",
      "        [-0.1587, -0.0661,  0.0834, -0.1311, -0.2272,  0.3123, -0.0329,  0.0409,\n",
      "         -0.0947],\n",
      "        [ 0.2214,  0.2853,  0.3061, -0.0523,  0.0145,  0.0965, -0.1408,  0.1369,\n",
      "         -0.3291],\n",
      "        [ 0.1187,  0.2921, -0.2262,  0.2194,  0.3228,  0.1973, -0.1867, -0.0499,\n",
      "          0.2422],\n",
      "        [ 0.3062,  0.1150,  0.2048,  0.1737,  0.0965,  0.2675, -0.0382,  0.0670,\n",
      "         -0.1761],\n",
      "        [-0.1165,  0.1994, -0.2552, -0.3250,  0.2293,  0.2107, -0.2794,  0.0915,\n",
      "          0.2739],\n",
      "        [-0.3079, -0.1039,  0.0683,  0.3278, -0.1047,  0.3118,  0.0968, -0.0632,\n",
      "         -0.1040],\n",
      "        [-0.2285,  0.2079, -0.2648,  0.1727, -0.3081,  0.0497,  0.1912,  0.0612,\n",
      "         -0.1779],\n",
      "        [ 0.0045, -0.2882,  0.2201,  0.2419,  0.1555,  0.3011, -0.0476, -0.2599,\n",
      "         -0.0583],\n",
      "        [-0.3172, -0.0804,  0.1037, -0.2915, -0.2245, -0.2403,  0.1103, -0.2353,\n",
      "          0.1523],\n",
      "        [ 0.2123,  0.0064,  0.0539, -0.1446, -0.0424, -0.2728,  0.2076, -0.1646,\n",
      "         -0.0537],\n",
      "        [-0.1358, -0.1095,  0.2673,  0.1012, -0.1836, -0.3300,  0.2334, -0.2069,\n",
      "          0.1380],\n",
      "        [ 0.1721, -0.0390, -0.1030,  0.1094, -0.1522,  0.1817, -0.0019, -0.0587,\n",
      "          0.1625],\n",
      "        [-0.3185, -0.2916, -0.2584, -0.0094,  0.0184, -0.0480,  0.0986, -0.0990,\n",
      "         -0.2985],\n",
      "        [-0.2580,  0.1738,  0.2276,  0.2145,  0.1179, -0.3268, -0.0795, -0.2723,\n",
      "          0.1887],\n",
      "        [ 0.0223, -0.0834, -0.1516, -0.2326,  0.0602,  0.2443,  0.0126, -0.2837,\n",
      "         -0.2900],\n",
      "        [-0.1090,  0.0821,  0.1580,  0.0991, -0.2490,  0.3026,  0.2820,  0.1293,\n",
      "          0.0599],\n",
      "        [ 0.1997,  0.1724, -0.0402,  0.0796,  0.1902, -0.0087, -0.2690, -0.2812,\n",
      "          0.3123],\n",
      "        [-0.2196,  0.1511,  0.0053, -0.2132, -0.0337,  0.0543, -0.0923, -0.0047,\n",
      "         -0.2105],\n",
      "        [-0.1494,  0.1552,  0.1228, -0.0897, -0.0137,  0.2002,  0.3285,  0.1522,\n",
      "         -0.2507],\n",
      "        [-0.0352,  0.2445,  0.2192, -0.1004,  0.2336, -0.1569,  0.1102,  0.2748,\n",
      "          0.2213],\n",
      "        [ 0.2663, -0.0526, -0.3242,  0.0093, -0.1258,  0.2620, -0.1231,  0.3106,\n",
      "         -0.1255],\n",
      "        [-0.1324, -0.0559, -0.0983,  0.1914, -0.0245, -0.0295,  0.2351,  0.0227,\n",
      "         -0.2342],\n",
      "        [ 0.3112, -0.0171,  0.2598, -0.1020, -0.2227, -0.1934,  0.0929,  0.2164,\n",
      "         -0.0070],\n",
      "        [ 0.1555,  0.1941,  0.3326, -0.1286, -0.1930,  0.1078,  0.3130,  0.1786,\n",
      "          0.2899],\n",
      "        [-0.1663, -0.1915, -0.1336,  0.0616, -0.1577, -0.1618,  0.1676, -0.1560,\n",
      "         -0.2693],\n",
      "        [ 0.1649,  0.1287, -0.3174, -0.2935,  0.2537,  0.0441, -0.2609,  0.1863,\n",
      "          0.1539],\n",
      "        [-0.2279,  0.2697, -0.1180, -0.1571, -0.1545, -0.1267,  0.0397, -0.0337,\n",
      "          0.0870],\n",
      "        [ 0.0595,  0.1769,  0.2982, -0.1327,  0.2791, -0.1398,  0.0685, -0.0417,\n",
      "          0.3294],\n",
      "        [-0.2272,  0.0677, -0.0473, -0.1053,  0.0719, -0.2528,  0.0868, -0.0312,\n",
      "         -0.0026],\n",
      "        [-0.1783, -0.0686, -0.1101, -0.0323,  0.2297, -0.2038, -0.1761,  0.1562,\n",
      "         -0.2657],\n",
      "        [-0.0914,  0.3332, -0.1306, -0.0089,  0.2145,  0.2531, -0.3238, -0.1737,\n",
      "         -0.0828],\n",
      "        [-0.3181, -0.0455,  0.1935,  0.1010, -0.2416, -0.2392,  0.1712, -0.0260,\n",
      "         -0.2882],\n",
      "        [ 0.1539, -0.0470, -0.2870,  0.1775, -0.3048,  0.0823,  0.0011, -0.1089,\n",
      "         -0.2029]], requires_grad=True)), ('layer_in.bias', Parameter containing:\n",
      "tensor([-0.2473,  0.3177,  0.1399,  0.0458, -0.2532,  0.0761,  0.3258,  0.2327,\n",
      "         0.1452,  0.0450, -0.1142,  0.2375, -0.3186,  0.1238, -0.0592, -0.1055,\n",
      "         0.0597, -0.2266,  0.0715,  0.1824,  0.3125,  0.0210, -0.0145,  0.0494,\n",
      "        -0.2035,  0.0769, -0.0749, -0.2440, -0.3313,  0.2829,  0.3238, -0.1643,\n",
      "         0.0433,  0.2242, -0.2431, -0.2264,  0.2412, -0.1586,  0.0928,  0.1233,\n",
      "        -0.0902, -0.0204, -0.2798,  0.1485, -0.2967,  0.1870, -0.0929,  0.0241,\n",
      "        -0.1667,  0.0431, -0.0524,  0.2973, -0.0412,  0.3186,  0.2859,  0.2401,\n",
      "         0.1296, -0.1989, -0.0422, -0.1966,  0.1679, -0.3104, -0.0767],\n",
      "       requires_grad=True)), ('layer_2.weight', Parameter containing:\n",
      "tensor([[-0.0189, -0.0535, -0.0683,  ..., -0.0775, -0.0826, -0.0121],\n",
      "        [ 0.0785, -0.0542, -0.0312,  ...,  0.0880,  0.0551,  0.0947],\n",
      "        [-0.0313, -0.0313, -0.0077,  ..., -0.0702,  0.0845, -0.0132],\n",
      "        ...,\n",
      "        [ 0.0623, -0.0379,  0.0126,  ...,  0.0470,  0.0342, -0.0560],\n",
      "        [-0.1221,  0.0521, -0.1165,  ...,  0.0600, -0.0894, -0.0222],\n",
      "        [-0.0051,  0.0184,  0.0683,  ...,  0.0092, -0.0563, -0.1073]],\n",
      "       requires_grad=True)), ('layer_2.bias', Parameter containing:\n",
      "tensor([-0.0614,  0.0963,  0.0773, -0.0669, -0.0111, -0.1215, -0.1103, -0.0057,\n",
      "         0.1105, -0.1163, -0.0644, -0.0864,  0.1217,  0.0918,  0.0251, -0.0845,\n",
      "         0.0057,  0.0259, -0.1211, -0.1159, -0.0203,  0.0895, -0.0412,  0.0429,\n",
      "        -0.0345,  0.0106,  0.1188,  0.0751,  0.0440, -0.0117,  0.0974, -0.0888,\n",
      "         0.0117, -0.0202, -0.0013, -0.0122, -0.0516,  0.0975, -0.1016,  0.0694,\n",
      "         0.0627,  0.0355, -0.1181,  0.1114,  0.0280,  0.1247,  0.0127,  0.0564,\n",
      "        -0.0340, -0.0749,  0.0305, -0.0597,  0.0238, -0.0641,  0.0811, -0.0633,\n",
      "        -0.0701, -0.0480,  0.0775, -0.0402,  0.0073, -0.0337,  0.0673],\n",
      "       requires_grad=True)), ('layer_out.weight', Parameter containing:\n",
      "tensor([[ 5.6796e-02, -2.8560e-02,  1.0708e-01,  8.1375e-02,  6.3501e-02,\n",
      "         -1.2237e-01, -6.0044e-02, -4.3405e-06,  6.6882e-03,  5.1867e-02,\n",
      "          1.8578e-02, -1.1260e-01,  1.0432e-01, -3.5573e-02,  9.8423e-02,\n",
      "          6.7990e-02, -1.0188e-01,  5.1932e-02, -6.3229e-02, -3.0848e-02,\n",
      "          1.1161e-01,  1.0860e-02,  2.4783e-02,  7.6241e-02, -1.1965e-01,\n",
      "          3.2024e-03, -8.8383e-02,  5.0170e-02,  5.0582e-04, -7.5046e-02,\n",
      "          4.1811e-02, -4.2560e-03, -2.3893e-02, -1.0679e-01,  8.9009e-02,\n",
      "          9.1992e-03,  1.1534e-01, -8.0334e-02, -7.9246e-02, -1.0975e-01,\n",
      "          1.0856e-01,  3.5514e-02,  7.3888e-02,  1.0836e-01,  8.1397e-02,\n",
      "          1.0623e-02,  7.4665e-04, -7.4376e-02, -1.5531e-02, -8.5730e-02,\n",
      "          2.1416e-02,  2.2173e-02,  4.3064e-02,  8.1785e-02, -1.2539e-01,\n",
      "          8.7481e-02,  7.6895e-02, -6.5308e-03,  6.4806e-02, -5.7965e-02,\n",
      "          1.2029e-01, -3.0198e-02,  1.1827e-01]], requires_grad=True)), ('layer_out.bias', Parameter containing:\n",
      "tensor([0.0376], requires_grad=True)), ('batchnorm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)), ('batchnorm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)), ('batchnorm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)), ('batchnorm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.named_parameters()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "outputs": [],
   "source": [
    "# Init loss function (Binary Cross Entropy Loss) (we assume that target is equally distributed)\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DataLoaders and Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before training, we should implement custom Dataset class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "outputs": [],
   "source": [
    "class TitanicTrainDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Return the single observation, including both independent and dependent variable \"\"\"\n",
    "        # Convert idx from tensor to list due to pandas bug (that arises when using pytorch's random_split)\n",
    "        # if isinstance(index, torch.Tensor):\n",
    "        #     index = index.tolist()\n",
    "\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        # return [self.X_data.iloc[index].values, self.y_data[index]]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Return the number of rows from tabular data \"\"\"\n",
    "        return len(self.X_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "outputs": [],
   "source": [
    "class TitanicTestDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Return the single observation, including only independent variable \"\"\"\n",
    "        if isinstance(index, torch.Tensor):\n",
    "            index = index.tolist()\n",
    "\n",
    "        return self.X_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Return the number of rows from tabular data \"\"\"\n",
    "        return len(self.X_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "outputs": [],
   "source": [
    "train_data = TitanicTrainDataset(torch.Tensor(X_train.values), torch.Tensor(y_train.values))\n",
    "test_data = TitanicTestDataset(torch.Tensor(X_test.values))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "outputs": [
    {
     "data": {
      "text/plain": "596"
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test len method\n",
    "train_data.__len__()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "outputs": [
    {
     "data": {
      "text/plain": "891"
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.__len__()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "outputs": [
    {
     "data": {
      "text/plain": "0    374\n1    222\nName: Survived, dtype: int64"
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([718.0000,   3.0000,  24.0000,   0.0000,   0.0000,  15.5000,   1.0000,\n           0.0000,   1.0000]),\n tensor(0.))"
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test getitem method\n",
    "train_data.__getitem__(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "outputs": [],
   "source": [
    "# Initialize dataloaders\n",
    "BATCH_SIZE_TRAIN = 64\n",
    "BATCH_SIZE_TEST = 1\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE_TEST, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "outputs": [],
   "source": [
    "# Define binary accuracy function\n",
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "\n",
    "    return acc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.72189 | Acc: 50.400\n",
      "Epoch 002: | Loss: 0.65755 | Acc: 66.100\n",
      "Epoch 003: | Loss: 0.64609 | Acc: 64.700\n",
      "Epoch 004: | Loss: 0.63892 | Acc: 67.600\n",
      "Epoch 005: | Loss: 0.62667 | Acc: 70.000\n",
      "Epoch 006: | Loss: 0.63114 | Acc: 65.100\n",
      "Epoch 007: | Loss: 0.62747 | Acc: 66.200\n",
      "Epoch 008: | Loss: 0.61022 | Acc: 68.100\n",
      "Epoch 009: | Loss: 0.60496 | Acc: 69.000\n",
      "Epoch 010: | Loss: 0.59772 | Acc: 68.000\n",
      "Epoch 011: | Loss: 0.59636 | Acc: 69.000\n",
      "Epoch 012: | Loss: 0.58457 | Acc: 69.500\n",
      "Epoch 013: | Loss: 0.59443 | Acc: 69.400\n",
      "Epoch 014: | Loss: 0.59562 | Acc: 69.900\n",
      "Epoch 015: | Loss: 0.61137 | Acc: 66.600\n",
      "Epoch 016: | Loss: 0.57027 | Acc: 70.500\n",
      "Epoch 017: | Loss: 0.58791 | Acc: 67.800\n",
      "Epoch 018: | Loss: 0.57017 | Acc: 69.600\n",
      "Epoch 019: | Loss: 0.55908 | Acc: 73.800\n",
      "Epoch 020: | Loss: 0.51940 | Acc: 74.400\n",
      "Epoch 021: | Loss: 0.47065 | Acc: 77.900\n",
      "Epoch 022: | Loss: 0.48797 | Acc: 77.700\n",
      "Epoch 023: | Loss: 0.47309 | Acc: 77.700\n",
      "Epoch 024: | Loss: 0.46964 | Acc: 77.600\n",
      "Epoch 025: | Loss: 0.44710 | Acc: 79.000\n",
      "Epoch 026: | Loss: 0.46131 | Acc: 78.600\n",
      "Epoch 027: | Loss: 0.45379 | Acc: 80.200\n",
      "Epoch 028: | Loss: 0.45732 | Acc: 79.100\n",
      "Epoch 029: | Loss: 0.44476 | Acc: 80.500\n",
      "Epoch 030: | Loss: 0.47844 | Acc: 77.500\n",
      "Epoch 031: | Loss: 0.48225 | Acc: 76.800\n",
      "Epoch 032: | Loss: 0.45095 | Acc: 78.400\n",
      "Epoch 033: | Loss: 0.44410 | Acc: 80.900\n",
      "Epoch 034: | Loss: 0.44738 | Acc: 80.800\n",
      "Epoch 035: | Loss: 0.44234 | Acc: 79.500\n",
      "Epoch 036: | Loss: 0.43762 | Acc: 78.600\n",
      "Epoch 037: | Loss: 0.42059 | Acc: 80.300\n",
      "Epoch 038: | Loss: 0.42685 | Acc: 80.800\n",
      "Epoch 039: | Loss: 0.43344 | Acc: 81.400\n",
      "Epoch 040: | Loss: 0.45300 | Acc: 78.500\n",
      "Epoch 041: | Loss: 0.45850 | Acc: 78.600\n",
      "Epoch 042: | Loss: 0.44837 | Acc: 80.200\n",
      "Epoch 043: | Loss: 0.40942 | Acc: 82.400\n",
      "Epoch 044: | Loss: 0.43642 | Acc: 78.500\n",
      "Epoch 045: | Loss: 0.43278 | Acc: 78.000\n",
      "Epoch 046: | Loss: 0.42879 | Acc: 80.600\n",
      "Epoch 047: | Loss: 0.41339 | Acc: 82.200\n",
      "Epoch 048: | Loss: 0.43513 | Acc: 79.300\n",
      "Epoch 049: | Loss: 0.41906 | Acc: 80.900\n",
      "Epoch 050: | Loss: 0.41989 | Acc: 82.200\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "# Prepare model for training (default state)\n",
    "model.train()\n",
    "\n",
    "for e in range(1, EPOCHS+1):\n",
    "\n",
    "    # Init loss and acc per epoch to zero\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    # For loop to get our data in batches from dataloader\n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "\n",
    "        # Load batches into memory (device)\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        # Set .grad attribute of all tensors to zero (otherwise we would accumulate it with .backwards())\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass (use input data to make prediction)\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        # Calculate loss based on prediction and true value\n",
    "        loss = loss_function(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "        # We backpropagate this error through the network\n",
    "        # The gradient is calculated for tensors which requires_grad=True\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust each parameter (weight and bias) by its gradient stored in .grad\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate loss and accuracy\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_dataloader):.5f} | Acc: {epoch_acc/len(train_dataloader):.3f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "\n",
    "# Prepare model for testing\n",
    "model.eval()\n",
    "\n",
    "# We don't want to perform backpropagation\n",
    "with torch.no_grad():\n",
    "\n",
    "    # Go through batches\n",
    "    for X_batch in test_dataloader:\n",
    "\n",
    "        # Load batch into memory\n",
    "        X_batch = X_batch.to(device)\n",
    "\n",
    "        # Get the result\n",
    "        y_test_pred = model(X_batch)\n",
    "\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "\n",
    "        # Round probabilities to 0 or 1\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "\n",
    "        # Convert tensor to numpy object\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "# Flatten the list to use confusion matrix and classification report\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[139,  36],\n       [ 24,  96]])"
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Plot confusion matrix\n",
    "confusion_matrix(y_test, y_pred_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82       175\n",
      "           1       0.73      0.80      0.76       120\n",
      "\n",
      "    accuracy                           0.80       295\n",
      "   macro avg       0.79      0.80      0.79       295\n",
      "weighted avg       0.80      0.80      0.80       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_list))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Submit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "outputs": [
    {
     "data": {
      "text/plain": "             index  Pclass   Age  SibSp  Parch      Fare  Embarked  Male  \\\nPassengerId                                                                \n892              0       3  34.5      0      0    7.8292         1   0.0   \n893              1       3  47.0      1      0    7.0000         2   1.0   \n894              2       2  62.0      0      0    9.6875         1   0.0   \n895              3       3  27.0      0      0    8.6625         2   0.0   \n896              4       3  22.0      1      1   12.2875         2   1.0   \n...            ...     ...   ...    ...    ...       ...       ...   ...   \n1305           413       3  24.0      0      0    8.0500         2   0.0   \n1306           414       1  39.0      0      0  108.9000         0   1.0   \n1307           415       3  38.5      0      0    7.2500         2   0.0   \n1308           416       3  24.0      0      0    8.0500         2   0.0   \n1309           417       3  24.0      1      1   22.3583         0   0.0   \n\n             Female  \nPassengerId          \n892             1.0  \n893             0.0  \n894             1.0  \n895             1.0  \n896             0.0  \n...             ...  \n1305            1.0  \n1306            0.0  \n1307            1.0  \n1308            1.0  \n1309            1.0  \n\n[418 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>Male</th>\n      <th>Female</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>892</th>\n      <td>0</td>\n      <td>3</td>\n      <td>34.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.8292</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>893</th>\n      <td>1</td>\n      <td>3</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.0000</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>894</th>\n      <td>2</td>\n      <td>2</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9.6875</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>895</th>\n      <td>3</td>\n      <td>3</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.6625</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>896</th>\n      <td>4</td>\n      <td>3</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>12.2875</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1305</th>\n      <td>413</td>\n      <td>3</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1306</th>\n      <td>414</td>\n      <td>1</td>\n      <td>39.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>108.9000</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1307</th>\n      <td>415</td>\n      <td>3</td>\n      <td>38.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1308</th>\n      <td>416</td>\n      <td>3</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1309</th>\n      <td>417</td>\n      <td>3</td>\n      <td>24.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>22.3583</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>418 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use fillna with most frequent values\n",
    "test.fillna(modes, inplace=True)\n",
    "test.reset_index(inplace=True)\n",
    "\n",
    "test.drop(columns=['Name', 'Ticket', 'Cabin'], inplace=True)\n",
    "\n",
    "# Use one_hot_encode for gender\n",
    "gender_test = one_hot_encoder.transform(test[['Sex']])\n",
    "gender_test_df = pd.DataFrame(gender_test.toarray(), columns=['Male', 'Female'])\n",
    "\n",
    "# Merge train with encoded gender\n",
    "test = pd.concat([test, gender_test_df], axis=1)\n",
    "\n",
    "# Drop unused column\n",
    "test.drop(columns=['Sex'], inplace=True)\n",
    "\n",
    "# Encode 'Embarked' with label encoder\n",
    "test['Embarked'] = label_encoder.transform(test['Embarked'])\n",
    "\n",
    "# Set PassangerID as index\n",
    "test.set_index('PassengerId', inplace=True)\n",
    "\n",
    "# Print\n",
    "test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "outputs": [],
   "source": [
    "# Apply model on test data\n",
    "sub_X = torch.tensor(test.values)\n",
    "\n",
    "# Get the results\n",
    "sub_y = titanic_network(sub_X.float())\n",
    "\n",
    "# Get survived\n",
    "survived = torch.heaviside(sub_y, values=torch.tensor([0.0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.]], grad_fn=<NotImplemented>)"
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survived"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "outputs": [],
   "source": [
    "test.reset_index(inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "outputs": [],
   "source": [
    "test['Survived'] = survived.detach().numpy().astype(int)\n",
    "sub_df = test[['PassengerId', 'Survived']]\n",
    "sub_df.to_csv('submission/sub-pytorch.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId,Survived\r\n",
      "892,0\r\n",
      "893,0\r\n",
      "894,0\r\n",
      "895,0\r\n",
      "896,0\r\n",
      "897,0\r\n",
      "898,1\r\n",
      "899,0\r\n",
      "900,1\r\n"
     ]
    }
   ],
   "source": [
    "!head 'submission/sub-fastai.csv'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
