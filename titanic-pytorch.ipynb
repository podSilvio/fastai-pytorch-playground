{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# Import train and test set\n",
    "train = pd.read_csv('titanic-dataset/train.csv')\n",
    "test = pd.read_csv('titanic-dataset/test.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# Get target values\n",
    "y = train['Survived']\n",
    "\n",
    "# Drop the Survived column and remove it from further calculations\n",
    "train.drop(columns=['Survived'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "(891, 11)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "(418, 11)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "(891,)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.shape)\n",
    "display(test.shape)\n",
    "display(y.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NaN values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "PassengerId      0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "train.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "PassengerId                      1\nPclass                         3.0\nName           Abbing, Mr. Anthony\nSex                           male\nAge                           24.0\nSibSp                          0.0\nParch                          0.0\nTicket                        1601\nFare                          8.05\nCabin                      B96 B98\nEmbarked                         S\nName: 0, dtype: object"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use mode() function to get the most frequent value\n",
    "modes = train.mode().iloc[0]\n",
    "modes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# Use fillna with most frequent values\n",
    "train.fillna(modes, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "train.isna().sum().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get rid of 'Name', 'Ticket' abd 'Cabin' variables\n",
    "**NOTE**: We don't use those values because right now it is out of scope. However, information in those variables are crucial and very imortant! The best score in Kaggle on Titanic dataset is performed only on 'Name' variable! See this notebook for more information: https://www.kaggle.com/code/cdeotte/titanic-using-name-only-0-81818/notebook\n",
    "**NOTE**: It's very common in tabular data to use *categorical embeddings*. This is on *TODO* list right after finishing this notebook."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "train.drop(columns=['Name', 'Ticket', 'Cabin'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Label encoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "     PassengerId  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n0              1       3    male  22.0      1      0   7.2500        S\n1              2       1  female  38.0      1      0  71.2833        C\n2              3       3  female  26.0      0      0   7.9250        S\n3              4       1  female  35.0      1      0  53.1000        S\n4              5       3    male  35.0      0      0   8.0500        S\n..           ...     ...     ...   ...    ...    ...      ...      ...\n886          887       2    male  27.0      0      0  13.0000        S\n887          888       1  female  19.0      0      0  30.0000        S\n888          889       3  female  24.0      1      2  23.4500        S\n889          890       1    male  26.0      0      0  30.0000        C\n890          891       3    male  32.0      0      0   7.7500        Q\n\n[891 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>887</td>\n      <td>2</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.0000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>3</td>\n      <td>female</td>\n      <td>24.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>23.4500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>890</td>\n      <td>1</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>3</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.7500</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore which variables are categorical\n",
    "train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "# Categorical varaibles are Pclass, Sex, Embarked - use one-hot encoding for gender and label for embarked\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "one_hot_encoder = OneHotEncoder()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "     PassengerId  Pclass   Age  SibSp  Parch     Fare  Embarked  Male  Female\n0              1       3  22.0      1      0   7.2500         2   0.0     1.0\n1              2       1  38.0      1      0  71.2833         0   1.0     0.0\n2              3       3  26.0      0      0   7.9250         2   1.0     0.0\n3              4       1  35.0      1      0  53.1000         2   1.0     0.0\n4              5       3  35.0      0      0   8.0500         2   0.0     1.0\n..           ...     ...   ...    ...    ...      ...       ...   ...     ...\n886          887       2  27.0      0      0  13.0000         2   0.0     1.0\n887          888       1  19.0      0      0  30.0000         2   1.0     0.0\n888          889       3  24.0      1      2  23.4500         2   1.0     0.0\n889          890       1  26.0      0      0  30.0000         0   0.0     1.0\n890          891       3  32.0      0      0   7.7500         1   0.0     1.0\n\n[891 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>Male</th>\n      <th>Female</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>887</td>\n      <td>2</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.0000</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>3</td>\n      <td>24.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>23.4500</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>890</td>\n      <td>1</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>3</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.7500</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use one_hot_encode for gender\n",
    "gender = one_hot_encoder.fit_transform(train[['Sex']])\n",
    "\n",
    "# Merge train with encoded gender\n",
    "train = train.merge(pd.DataFrame(gender.toarray(), columns=['Male', 'Female']), left_index=True, right_index=True)\n",
    "\n",
    "# Drop unused column\n",
    "train.drop(columns=['Sex'], inplace=True)\n",
    "\n",
    "# Encode 'Embarked' with label encoder\n",
    "train['Embarked'] = label_encoder.fit_transform(train['Embarked'])\n",
    "\n",
    "# Print\n",
    "train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use the same preprocessing techniques for test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "test.drop(columns=['Name', 'Ticket', 'Cabin'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "     PassengerId  Pclass   Age  SibSp  Parch      Fare  Embarked  Male  Female\n0            892       3  34.5      0      0    7.8292         1   0.0     1.0\n1            893       3  47.0      1      0    7.0000         2   1.0     0.0\n2            894       2  62.0      0      0    9.6875         1   0.0     1.0\n3            895       3  27.0      0      0    8.6625         2   0.0     1.0\n4            896       3  22.0      1      1   12.2875         2   1.0     0.0\n..           ...     ...   ...    ...    ...       ...       ...   ...     ...\n413         1305       3   NaN      0      0    8.0500         2   0.0     1.0\n414         1306       1  39.0      0      0  108.9000         0   1.0     0.0\n415         1307       3  38.5      0      0    7.2500         2   0.0     1.0\n416         1308       3   NaN      0      0    8.0500         2   0.0     1.0\n417         1309       3   NaN      1      1   22.3583         0   0.0     1.0\n\n[418 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>Male</th>\n      <th>Female</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>3</td>\n      <td>34.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.8292</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>3</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.0000</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>2</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9.6875</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>3</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.6625</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>3</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>12.2875</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>413</th>\n      <td>1305</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>414</th>\n      <td>1306</td>\n      <td>1</td>\n      <td>39.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>108.9000</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>415</th>\n      <td>1307</td>\n      <td>3</td>\n      <td>38.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>416</th>\n      <td>1308</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>417</th>\n      <td>1309</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>22.3583</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>418 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use one_hot_encode for gender\n",
    "gender = one_hot_encoder.fit_transform(test[['Sex']])\n",
    "\n",
    "# Merge train with encoded gender\n",
    "test = test.merge(pd.DataFrame(gender.toarray(), columns=['Male', 'Female']), left_index=True, right_index=True)\n",
    "\n",
    "# Drop unused column\n",
    "test.drop(columns=['Sex'], inplace=True)\n",
    "\n",
    "# Encode 'Embarked' with label encoder\n",
    "test['Embarked'] = label_encoder.fit_transform(test['Embarked'])\n",
    "\n",
    "# Print\n",
    "test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "(891, 9)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "(418, 9)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check whether the dimensions are correct\n",
    "display(train.shape)\n",
    "display(test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# Define the class\n",
    "class TitanicNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TitanicNetwork, self).__init__()\n",
    "\n",
    "        # Number of input features is 9\n",
    "        self.layer_in = nn.Linear(9, 36)\n",
    "        self.layer_2 = nn.Linear(36, 36)\n",
    "        self.layer_out = nn.Linear(36,1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(36)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_in(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Note**: that we did not use the Sigmoid activation in our final layer during training. That’s because, we use the nn.BCEWithLogitsLoss() loss function which automatically applies the Sigmoid activation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "TitanicNetwork(\n  (layer_in): Linear(in_features=9, out_features=36, bias=True)\n  (layer_2): Linear(in_features=36, out_features=36, bias=True)\n  (layer_out): Linear(in_features=36, out_features=1, bias=True)\n  (relu): ReLU()\n  (dropout): Dropout(p=0.1, inplace=False)\n  (batchnorm1): BatchNorm1d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n)"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = TitanicNetwork()\n",
    "\n",
    "# Specify the device type responsible to load model into memory\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TitanicNetwork(\n",
      "  (layer_in): Linear(in_features=9, out_features=36, bias=True)\n",
      "  (layer_2): Linear(in_features=36, out_features=36, bias=True)\n",
      "  (layer_out): Linear(in_features=36, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('layer_in.weight', Parameter containing:\n",
      "tensor([[ 0.0557, -0.2613,  0.0586,  0.1018, -0.1719,  0.3269,  0.2270,  0.1842,\n",
      "          0.1527],\n",
      "        [-0.0396, -0.0199,  0.0333,  0.2156,  0.1851,  0.0743,  0.1887, -0.1132,\n",
      "          0.0048],\n",
      "        [ 0.2750, -0.3151,  0.2268, -0.1052,  0.1912,  0.3188, -0.2516,  0.1852,\n",
      "          0.0044],\n",
      "        [-0.3325, -0.2183, -0.1954, -0.3271, -0.1158,  0.1129,  0.2384, -0.1345,\n",
      "         -0.0847],\n",
      "        [-0.2663, -0.0976,  0.0794, -0.0964,  0.2563, -0.2181, -0.0504, -0.0982,\n",
      "          0.1203],\n",
      "        [-0.2882,  0.1759, -0.2677,  0.2191,  0.0739, -0.2554, -0.1136,  0.2131,\n",
      "         -0.3157],\n",
      "        [-0.2592, -0.0279, -0.1885,  0.0361, -0.2181,  0.1029,  0.3166,  0.1213,\n",
      "         -0.2273],\n",
      "        [-0.3153, -0.2160, -0.2170, -0.1859,  0.0770,  0.2835,  0.2916, -0.1762,\n",
      "         -0.0927],\n",
      "        [-0.0537,  0.1690, -0.2783,  0.2494,  0.2160,  0.2826,  0.1458, -0.0816,\n",
      "         -0.1394],\n",
      "        [ 0.0402,  0.3094,  0.2060, -0.1390, -0.2516,  0.1834,  0.0613, -0.1078,\n",
      "         -0.2285],\n",
      "        [-0.1596,  0.2049, -0.2740, -0.2549,  0.0119,  0.0712,  0.0904, -0.3236,\n",
      "          0.0397],\n",
      "        [-0.2814,  0.0004,  0.0882, -0.3191,  0.0808,  0.1235, -0.2882, -0.2732,\n",
      "          0.0324],\n",
      "        [-0.2300, -0.2712, -0.1366, -0.1474,  0.0361,  0.0574, -0.0673,  0.0036,\n",
      "          0.0345],\n",
      "        [-0.0184,  0.2399, -0.2815,  0.0532,  0.0555, -0.1945,  0.2648, -0.0806,\n",
      "          0.1108],\n",
      "        [-0.1428, -0.2529, -0.2479,  0.1636, -0.1158,  0.1330, -0.2934, -0.1475,\n",
      "          0.2608],\n",
      "        [-0.3023,  0.1702, -0.2173,  0.0261,  0.0815, -0.0971,  0.1718,  0.2336,\n",
      "          0.2551],\n",
      "        [ 0.2361,  0.2913, -0.1256,  0.1534, -0.2069, -0.0753,  0.0123, -0.2757,\n",
      "          0.1724],\n",
      "        [-0.2231,  0.1162,  0.2405,  0.1129, -0.2394, -0.1266,  0.2288, -0.3191,\n",
      "          0.1276],\n",
      "        [ 0.0538, -0.1269,  0.1763,  0.1995,  0.2727, -0.0415,  0.2224,  0.2328,\n",
      "         -0.0516],\n",
      "        [-0.1625, -0.3143, -0.0833,  0.0660,  0.3196,  0.3061,  0.0379,  0.0601,\n",
      "          0.0164],\n",
      "        [-0.0586, -0.3102,  0.0590,  0.0743, -0.3286, -0.0603, -0.2875,  0.2492,\n",
      "          0.1679],\n",
      "        [-0.1368,  0.1410, -0.1289,  0.2882,  0.0638, -0.2184, -0.2837,  0.2188,\n",
      "         -0.2368],\n",
      "        [ 0.2833, -0.2648,  0.0676, -0.0860, -0.2973, -0.1286,  0.0066,  0.2857,\n",
      "          0.2648],\n",
      "        [ 0.2509,  0.1734, -0.2044, -0.2173,  0.2484, -0.1593, -0.1229,  0.2563,\n",
      "          0.3168],\n",
      "        [ 0.3125,  0.0353,  0.0199,  0.3115,  0.0942,  0.2336,  0.0424, -0.2454,\n",
      "          0.2964],\n",
      "        [-0.3201,  0.3142,  0.1225,  0.0198,  0.1049, -0.0896,  0.0444,  0.0712,\n",
      "         -0.2413],\n",
      "        [ 0.2442,  0.1132, -0.1963,  0.1410,  0.0451, -0.1397,  0.2447,  0.2077,\n",
      "          0.1784],\n",
      "        [ 0.0239,  0.0857, -0.1041,  0.2861, -0.0928, -0.0890, -0.0930,  0.0867,\n",
      "          0.3308],\n",
      "        [ 0.2618,  0.2559,  0.3122, -0.2535,  0.3284,  0.0746, -0.1579, -0.3084,\n",
      "          0.3317],\n",
      "        [-0.0930,  0.2193,  0.2344,  0.1859,  0.0249, -0.2729, -0.0234,  0.1032,\n",
      "         -0.2531],\n",
      "        [-0.2247,  0.1823, -0.0695, -0.1164, -0.2401, -0.0006, -0.2116, -0.2204,\n",
      "         -0.2138],\n",
      "        [-0.2273, -0.2083,  0.0619, -0.2703,  0.0347,  0.1558,  0.0253,  0.1480,\n",
      "          0.2151],\n",
      "        [-0.2350,  0.2915, -0.3019,  0.1133, -0.0175, -0.0683, -0.0692,  0.1605,\n",
      "          0.1672],\n",
      "        [-0.2712, -0.0686, -0.3121, -0.0829, -0.3274, -0.1678,  0.2939,  0.3083,\n",
      "         -0.1320],\n",
      "        [-0.0287, -0.2161, -0.2350, -0.0004,  0.0610, -0.0820, -0.0997, -0.2943,\n",
      "          0.2298],\n",
      "        [ 0.2834, -0.2417, -0.1343,  0.2373, -0.2194,  0.1309,  0.2400, -0.1859,\n",
      "          0.0296]], requires_grad=True)), ('layer_in.bias', Parameter containing:\n",
      "tensor([ 0.2541,  0.1977,  0.1707,  0.2129,  0.1264, -0.2496,  0.1243,  0.1511,\n",
      "        -0.2310,  0.0642, -0.1158, -0.1483, -0.2334, -0.1755,  0.2691,  0.1696,\n",
      "        -0.0710, -0.0820,  0.2481, -0.2083,  0.3144, -0.0591,  0.2042,  0.0861,\n",
      "        -0.1082, -0.1674, -0.3094,  0.0380, -0.2731, -0.2350, -0.1176, -0.1227,\n",
      "        -0.2758, -0.2128, -0.2320,  0.0235], requires_grad=True)), ('layer_2.weight', Parameter containing:\n",
      "tensor([[-0.0467,  0.0584, -0.0318,  ...,  0.0831,  0.0805,  0.1072],\n",
      "        [ 0.0866,  0.1322,  0.0380,  ..., -0.1650, -0.1146,  0.1046],\n",
      "        [-0.1439, -0.1597, -0.1514,  ..., -0.0463, -0.1257, -0.1392],\n",
      "        ...,\n",
      "        [-0.1379, -0.1036,  0.1636,  ...,  0.1486, -0.0271,  0.0478],\n",
      "        [ 0.0432,  0.0485, -0.0412,  ...,  0.0403, -0.1162,  0.0183],\n",
      "        [ 0.0589, -0.1659,  0.0381,  ...,  0.0273, -0.1160, -0.0546]],\n",
      "       requires_grad=True)), ('layer_2.bias', Parameter containing:\n",
      "tensor([ 0.0743, -0.0897,  0.0870, -0.1183, -0.1043,  0.1511,  0.0910,  0.1562,\n",
      "         0.0998, -0.0963, -0.0932,  0.1147, -0.1407, -0.1036, -0.0031, -0.1089,\n",
      "        -0.0449, -0.0494,  0.0397,  0.0983, -0.0562, -0.1293,  0.0387, -0.1296,\n",
      "         0.0702,  0.0805, -0.1363, -0.1475,  0.1611,  0.0813,  0.0677, -0.1280,\n",
      "        -0.1080, -0.0601, -0.0069, -0.0952], requires_grad=True)), ('layer_out.weight', Parameter containing:\n",
      "tensor([[-0.0652, -0.0394, -0.1061,  0.1238,  0.0204, -0.0218,  0.0340, -0.1313,\n",
      "          0.1099,  0.1424,  0.0193,  0.0454,  0.1335, -0.0371, -0.0330, -0.0990,\n",
      "          0.0912, -0.1390,  0.0921, -0.0352, -0.0347,  0.1214,  0.0694,  0.0714,\n",
      "         -0.0278,  0.0144, -0.1278, -0.1527,  0.1627, -0.0865,  0.0935, -0.0743,\n",
      "          0.1589,  0.1186, -0.0912, -0.1631]], requires_grad=True)), ('layer_out.bias', Parameter containing:\n",
      "tensor([0.0247], requires_grad=True)), ('batchnorm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True)), ('batchnorm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.named_parameters()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# Init loss function (Binary Cross Entropy Loss) (we assume that target is equally distributed)\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DataLoaders and Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before training, we should implement custom Dataset class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "class TitanicTrainDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Return the single observation, including both independent and dependent variable \"\"\"\n",
    "        # Convert idx from tensor to list due to pandas bug (that arises when using pytorch's random_split)\n",
    "        if isinstance(index, torch.Tensor):\n",
    "            index = index.tolist()\n",
    "\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        # return [self.X_data.iloc[index].values, self.y_data[index]]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Return the number of rows from tabular data \"\"\"\n",
    "        return len(self.X_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "class TitanicTestDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Return the single observation, including only independent variable \"\"\"\n",
    "        if isinstance(index, torch.Tensor):\n",
    "            index = index.tolist()\n",
    "\n",
    "        return self.X_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Return the number of rows from tabular data \"\"\"\n",
    "        return len(self.X_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "train_data = TitanicTrainDataset(torch.Tensor(train.values), torch.Tensor(y.values))\n",
    "test_data = TitanicTestDataset(torch.Tensor(test.values))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "891"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test len method\n",
    "train_data.__len__()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([ 2.0000,  1.0000, 38.0000,  1.0000,  0.0000, 71.2833,  0.0000,  1.0000,\n          0.0000]),\n tensor(1.))"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test getitem method\n",
    "train_data.__getitem__(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "# Initialize dataloaders\n",
    "BATCH_SIZE_TRAIN = 64\n",
    "BATCH_SIZE_TEST = 1\n",
    "train_dataloader = DataLoader(dataset=train, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test, batch_size=BATCH_SIZE_TEST, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Init dataloaders\n",
    "train_loader = DataFrame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
